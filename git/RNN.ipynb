{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 知识区域：\n",
    "1. apply 函数的用法； \n",
    "    * 作用于字典dic.items()，列表，元组等可迭代的数据结构\n",
    "    * 效果： 其中每个元素为自变量，apply的函数\n",
    "    * 例子如下：\n",
    "    \n",
    "    ``` datalist  = list(data['text'])\n",
    "    cutfun = lambda x: list(jieba.cut(x))\n",
    "    senctences = data['text'].apply(cutfun)\n",
    "2. jieba 的用法：\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from gensim.corpora import dictionary\n",
    "from gensim import corpora,models,similarities\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from sklearn.model_selection import cross_validate \n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile, common_texts\n",
    "from keras import Sequential\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import sequence\n",
    "import keras\n",
    "import jieba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pic</td>\n",
       "      <td>高清：彭帅谢淑薇遗憾遭逆转出局 击掌互相鼓励责编:马克杰 日期:2013-10-4 彭帅谢淑...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>河南周口路边秸秆燃烧 2岁幼儿被熏晕(图)  10月3日下午,崔先生驾车去周口郸城县汲冢镇走...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news</td>\n",
       "      <td>消息称138名中国劳工在菲律宾被抓 使馆正核实【使馆正核实情况】中国驻菲律宾大使馆发言人表示...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>越南重要军事领导人武元甲大将去世 享年102岁据美国媒体10月4日报道, 越南抗法、抗美战争...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news</td>\n",
       "      <td>西沙搜救已发现6具遇难渔民遗体 尚有52人失踪【已发现6具遇难渔民遗体 尚有52人失踪】10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   pic  高清：彭帅谢淑薇遗憾遭逆转出局 击掌互相鼓励责编:马克杰 日期:2013-10-4 彭帅谢淑...\n",
       "1  news  河南周口路边秸秆燃烧 2岁幼儿被熏晕(图)  10月3日下午,崔先生驾车去周口郸城县汲冢镇走...\n",
       "2  news  消息称138名中国劳工在菲律宾被抓 使馆正核实【使馆正核实情况】中国驻菲律宾大使馆发言人表示...\n",
       "3  news  越南重要军事领导人武元甲大将去世 享年102岁据美国媒体10月4日报道, 越南抗法、抗美战争...\n",
       "4  news  西沙搜救已发现6具遇难渔民遗体 尚有52人失踪【已发现6具遇难渔民遗体 尚有52人失踪】10..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loas data\n",
    "data = pd.read_csv(\"sohu.csv\")\n",
    "labels = data['label']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pic', 'news', 'sports', 'business', 'caipiao', 'yule', 'mil', 'cul']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeltag=list(labels.unique())\n",
    "print(labeltag)\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(labeltag)):\n",
    "        if(labels[i]==labeltag[j]):\n",
    "            labels[i]=j\n",
    "            break\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先用jieba 分词， 然后生成list of wordlist \n",
    "# 然后将它放到 word2vecor 里面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['高清',\n",
       "  '：',\n",
       "  '彭帅',\n",
       "  '谢淑薇',\n",
       "  '遗憾',\n",
       "  '遭',\n",
       "  '逆转',\n",
       "  '出局',\n",
       "  ' ',\n",
       "  '击掌',\n",
       "  '互相',\n",
       "  '鼓励',\n",
       "  '责编',\n",
       "  ':',\n",
       "  '马克',\n",
       "  '杰',\n",
       "  ' ',\n",
       "  '日期',\n",
       "  ':',\n",
       "  '2013',\n",
       "  '-',\n",
       "  '10',\n",
       "  '-',\n",
       "  '4',\n",
       "  ' ',\n",
       "  '彭帅',\n",
       "  '谢淑薇',\n",
       "  '互相',\n",
       "  '鼓励',\n",
       "  ' ',\n",
       "  '北京',\n",
       "  '时间',\n",
       "  '10',\n",
       "  '月',\n",
       "  '4',\n",
       "  '日',\n",
       "  '消息',\n",
       "  ',',\n",
       "  '2013',\n",
       "  '年',\n",
       "  '中国',\n",
       "  '网球',\n",
       "  '公开赛',\n",
       "  '结束',\n",
       "  '了',\n",
       "  '一场',\n",
       "  '女双',\n",
       "  '半决赛',\n",
       "  '的',\n",
       "  '争夺',\n",
       "  ',',\n",
       "  '赛会',\n",
       "  '2',\n",
       "  '号',\n",
       "  '种子',\n",
       "  '―',\n",
       "  '―',\n",
       "  '我国',\n",
       "  '金花',\n",
       "  '彭帅',\n",
       "  '和',\n",
       "  '中华',\n",
       "  '台北',\n",
       "  '名将',\n",
       "  '谢淑薇',\n",
       "  '的',\n",
       "  '海峡',\n",
       "  '组合',\n",
       "  '错过',\n",
       "  '了',\n",
       "  '先胜',\n",
       "  '一盘',\n",
       "  '、',\n",
       "  '抢',\n",
       "  '十局',\n",
       "  '8',\n",
       "  '-',\n",
       "  '4',\n",
       "  '领先',\n",
       "  '的',\n",
       "  '优势',\n",
       "  ',',\n",
       "  '连',\n",
       "  '丢',\n",
       "  '六分',\n",
       "  '之后',\n",
       "  '以',\n",
       "  '6',\n",
       "  '-',\n",
       "  '3',\n",
       "  '/',\n",
       "  '1',\n",
       "  '-',\n",
       "  '6',\n",
       "  '/',\n",
       "  '8',\n",
       "  '-',\n",
       "  '10',\n",
       "  '惨遭',\n",
       "  '逆转',\n",
       "  ',',\n",
       "  '无缘',\n",
       "  '女双',\n",
       "  '决赛',\n",
       "  '。',\n",
       "  '(',\n",
       "  '搜狐',\n",
       "  '-',\n",
       "  '李志岩',\n",
       "  '/',\n",
       "  '摄',\n",
       "  ')'],\n",
       " ['河南',\n",
       "  '周口',\n",
       "  '路边',\n",
       "  '秸秆',\n",
       "  '燃烧',\n",
       "  ' ',\n",
       "  '2',\n",
       "  '岁',\n",
       "  '幼儿',\n",
       "  '被',\n",
       "  '熏',\n",
       "  '晕',\n",
       "  '(',\n",
       "  '图',\n",
       "  ')',\n",
       "  '\\xa0',\n",
       "  ' ',\n",
       "  '10',\n",
       "  '月',\n",
       "  '3',\n",
       "  '日',\n",
       "  '下午',\n",
       "  ',',\n",
       "  '崔先生',\n",
       "  '驾车',\n",
       "  '去',\n",
       "  '周口',\n",
       "  '郸城县',\n",
       "  '汲冢镇',\n",
       "  '走亲戚',\n",
       "  '时',\n",
       "  ',',\n",
       "  '乡间',\n",
       "  '道路',\n",
       "  '两边',\n",
       "  '的',\n",
       "  '秸秆',\n",
       "  '被',\n",
       "  '点燃',\n",
       "  ',',\n",
       "  '浓烟',\n",
       "  '和',\n",
       "  '大火',\n",
       "  '“',\n",
       "  '封锁',\n",
       "  '”',\n",
       "  '了',\n",
       "  '道路',\n",
       "  '。',\n",
       "  '在',\n",
       "  '躲避',\n",
       "  '大火',\n",
       "  '过程',\n",
       "  '中',\n",
       "  ',',\n",
       "  '崔先生',\n",
       "  '2',\n",
       "  '岁',\n",
       "  '的',\n",
       "  '儿子',\n",
       "  '被',\n",
       "  '熏',\n",
       "  '晕',\n",
       "  ',',\n",
       "  '车上',\n",
       "  '另一名',\n",
       "  '5',\n",
       "  '岁',\n",
       "  '的',\n",
       "  '男童',\n",
       "  '头发',\n",
       "  '被',\n",
       "  '大面积',\n",
       "  '烧焦',\n",
       "  ',',\n",
       "  '崔先生',\n",
       "  '妻子',\n",
       "  '的',\n",
       "  '腿部',\n",
       "  '被',\n",
       "  '烧伤',\n",
       "  '。',\n",
       "  ' ',\n",
       "  '据',\n",
       "  '崔先生',\n",
       "  '介绍',\n",
       "  ',',\n",
       "  '3',\n",
       "  '日',\n",
       "  '下午',\n",
       "  '3',\n",
       "  '时许',\n",
       "  ',',\n",
       "  '他',\n",
       "  '驾驶',\n",
       "  '一辆',\n",
       "  '轿车',\n",
       "  '去',\n",
       "  '郸城县',\n",
       "  '汲冢镇',\n",
       "  '走亲戚',\n",
       "  '。',\n",
       "  '车子',\n",
       "  '行驶',\n",
       "  '在',\n",
       "  '该镇',\n",
       "  '李寨村',\n",
       "  '南头',\n",
       "  '的',\n",
       "  '乡间',\n",
       "  '道路',\n",
       "  '上时',\n",
       "  ',',\n",
       "  '两边',\n",
       "  '农田',\n",
       "  '里',\n",
       "  '及',\n",
       "  '路上',\n",
       "  '堆积',\n",
       "  '的',\n",
       "  '秸秆',\n",
       "  '被',\n",
       "  '点燃',\n",
       "  '。',\n",
       "  '霎时间',\n",
       "  ',',\n",
       "  '大火',\n",
       "  '和',\n",
       "  '浓烟',\n",
       "  '封锁',\n",
       "  '了',\n",
       "  '前行',\n",
       "  '的',\n",
       "  '道路',\n",
       "  '。',\n",
       "  '崔先生',\n",
       "  '让',\n",
       "  '妻子',\n",
       "  '带领',\n",
       "  '车上',\n",
       "  '的',\n",
       "  '两名',\n",
       "  '幼儿',\n",
       "  '下车',\n",
       "  '逃离现场',\n",
       "  ',',\n",
       "  '他',\n",
       "  '自己',\n",
       "  '倒车',\n",
       "  '躲避',\n",
       "  '大火',\n",
       "  '。',\n",
       "  '逃跑',\n",
       "  '中',\n",
       "  ',',\n",
       "  '崔先生',\n",
       "  '2',\n",
       "  '岁',\n",
       "  '的',\n",
       "  '儿子',\n",
       "  '崔伟',\n",
       "  '被',\n",
       "  '熏',\n",
       "  '晕',\n",
       "  ',',\n",
       "  '车上',\n",
       "  '5',\n",
       "  '岁',\n",
       "  '男童',\n",
       "  '钱义',\n",
       "  '的',\n",
       "  '头发',\n",
       "  '被',\n",
       "  '大面积',\n",
       "  '烧焦',\n",
       "  ',',\n",
       "  '而',\n",
       "  '崔先生',\n",
       "  '妻子',\n",
       "  '的',\n",
       "  '腿',\n",
       "  '上',\n",
       "  '被',\n",
       "  '烫出',\n",
       "  '了',\n",
       "  '很多',\n",
       "  '水泡',\n",
       "  '。',\n",
       "  ' ',\n",
       "  '记者',\n",
       "  '昨日',\n",
       "  '从',\n",
       "  '崔先生',\n",
       "  '提供',\n",
       "  '的',\n",
       "  '照片',\n",
       "  '中',\n",
       "  '看到',\n",
       "  ',',\n",
       "  '不算',\n",
       "  '宽敞',\n",
       "  '的',\n",
       "  '小',\n",
       "  '路边',\n",
       "  '一堆',\n",
       "  '着火',\n",
       "  '的',\n",
       "  '秸秆',\n",
       "  '冒',\n",
       "  '出',\n",
       "  '滚滚',\n",
       "  '白烟',\n",
       "  ',',\n",
       "  '浓烟',\n",
       "  '笼罩',\n",
       "  '在',\n",
       "  '道路',\n",
       "  '上',\n",
       "  '根本无法',\n",
       "  '看清',\n",
       "  '对面',\n",
       "  '的',\n",
       "  '情况',\n",
       "  '。',\n",
       "  '崔先生',\n",
       "  '说',\n",
       "  ',',\n",
       "  '道路',\n",
       "  '是',\n",
       "  '南北',\n",
       "  '走向',\n",
       "  ',',\n",
       "  '长达',\n",
       "  '100',\n",
       "  '米',\n",
       "  '的',\n",
       "  '路段',\n",
       "  '两边',\n",
       "  '秸秆',\n",
       "  '被',\n",
       "  '引燃',\n",
       "  '。',\n",
       "  ' ',\n",
       "  '“',\n",
       "  '大火',\n",
       "  '着',\n",
       "  '了',\n",
       "  '近',\n",
       "  '4',\n",
       "  '个',\n",
       "  '小时',\n",
       "  ',',\n",
       "  '后来',\n",
       "  '被',\n",
       "  '消防人员',\n",
       "  '扑灭',\n",
       "  '了',\n",
       "  '。',\n",
       "  '”',\n",
       "  '崔先生',\n",
       "  '说',\n",
       "  ',',\n",
       "  '事后',\n",
       "  '他',\n",
       "  '本人',\n",
       "  '感到',\n",
       "  '头晕',\n",
       "  '、',\n",
       "  '胸闷',\n",
       "  ',',\n",
       "  '被',\n",
       "  '120',\n",
       "  '拉到',\n",
       "  '医院',\n",
       "  '抢救',\n",
       "  ',',\n",
       "  '目前',\n",
       "  '症状',\n",
       "  '已',\n",
       "  '减退',\n",
       "  ',',\n",
       "  '两名',\n",
       "  '幼童',\n",
       "  '也',\n",
       "  '无',\n",
       "  '大碍',\n",
       "  ',',\n",
       "  '只有',\n",
       "  '他',\n",
       "  '妻子',\n",
       "  '的',\n",
       "  '腿部',\n",
       "  '仍带',\n",
       "  '烫伤',\n",
       "  '。',\n",
       "  '“',\n",
       "  '我们',\n",
       "  '的',\n",
       "  '医疗费',\n",
       "  '该',\n",
       "  '谁',\n",
       "  '承担',\n",
       "  '呢',\n",
       "  '?',\n",
       "  '”',\n",
       "  '崔先生',\n",
       "  '不解',\n",
       "  '地说',\n",
       "  '。',\n",
       "  '而',\n",
       "  '对于',\n",
       "  '其',\n",
       "  '驾驶',\n",
       "  '的',\n",
       "  '轿车',\n",
       "  '是否',\n",
       "  '受损',\n",
       "  ',',\n",
       "  '崔先生',\n",
       "  '说',\n",
       "  '还',\n",
       "  '未',\n",
       "  '来得及',\n",
       "  '检测',\n",
       "  '。',\n",
       "  '(',\n",
       "  '大河',\n",
       "  '报',\n",
       "  '记者',\n",
       "  ' ',\n",
       "  '于扬',\n",
       "  ' ',\n",
       "  '实习生',\n",
       "  ' ',\n",
       "  '李玉坤',\n",
       "  ')']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分词\n",
    "datalist = list(data['text'])\n",
    "length = len(datalist)\n",
    "# 分词\n",
    "# 定义分词函数\n",
    "sentences = []\n",
    "for i in range(length):\n",
    "    split_text = list(jieba.cut(datalist[i]))\n",
    "    sentences.append(split_text)# list 的list \n",
    "sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\1installs\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \n",
      "D:\\1installs\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "# 训练Word2vec模型\n",
    "\n",
    "model = Word2Vec(\n",
    "                 size=100,  # 词向量维度\n",
    "                 min_count=5,  # 词频阈值\n",
    "                 window=5)  # 窗口大小\n",
    "model.build_vocab(sentences)\n",
    "model.train(sentences,total_examples = model.corpus_count,epochs = model.iter)\n",
    "model.save('souhu.model')# 保存模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\1installs\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36572\n"
     ]
    }
   ],
   "source": [
    "modelw = Word2Vec.load('kesic2.model')# 加载模型\n",
    "print(len(modelw.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\1installs\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "gensim_dict = dictionary.Dictionary()\n",
    "\n",
    "gensim_dict.doc2bow(model.wv.vocab.keys(), allow_update=True)\n",
    "w2indx = {v: k + 1 for k, v in gensim_dict.items()}  # K ：索引，V： vactary，词语的索引，从1开始编号 print(w2indx)\n",
    "w2vec = {word: model[word] for word in w2indx.keys()}  # 词语的词向量\n",
    "#corpora.MmCorpus.serialize('textmatrix.mm', corpus) # 存入硬盘，以备后需\n",
    "# gensim_dict.doc2bow(model.vocab.keys(), allow_update=True)\n",
    "# 存起来\n",
    "output = open(\"souhu.pkl\", 'wb')\n",
    "pickle.dump(w2indx, output)  # 索引字典\n",
    "pickle.dump(w2vec, output)  # 词向量字典\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取大语料文本\n",
    "f = open(\"souhu.pkl\", 'rb')  # 预先训练好的\n",
    "index_dict = pickle.load(f)  # 索引字典，{单词: 索引数字}\n",
    "word_vectors = pickle.load(f)  # 词向量, {单词: 词向量(100维长的数组)}\n",
    "# word_vectors.values().shape\n",
    "\n",
    "new_dic = index_dict\n",
    "print(len(new_dic))\n",
    "word_length = word_vectors['19'].shape[0]\n",
    "word_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Arrays for Keras Embedding Layer...\n"
     ]
    }
   ],
   "source": [
    "# 创建权重矩阵\n",
    "print (u\"Setting up Arrays for Keras Embedding Layer...\")\n",
    "n_symbols = len(index_dict) + 1  # 索引数字的个数，因为有的词语索引为0，所以+1\n",
    "#embedding_weights = np.zeros((n_symbols,word_length))  # 创建一个n_symbols * word_length的0矩阵\n",
    "embedding_weights = ((np.random.rand(n_symbols,word_length)) - 0.5) / 5.0  # 创建一个随机初始化一个 n_symbols * word_length的矩阵\n",
    "for w, index in index_dict.items():  # 从索引为1的词语开始，用词向量填充矩阵\n",
    "    embedding_weights[index, :] = word_vectors[w]  # 词向量矩阵，第一行是0向量（没有索引为0的词语，未被填充）\n",
    "# embedding_weights[2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(sentences, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_index_array(p_new_dic, p_sen):  # 文本转为索引数字模式\n",
    "    new_sentences = []\n",
    "    for sen in p_sen:\n",
    "        new_sen = []\n",
    "        for word in sen:\n",
    "            try:\n",
    "                new_sen.append(p_new_dic[word])  # 单词转索引数字\n",
    "            except:\n",
    "                new_sen.append(0)  # 索引字典里没有的词转为数字0\n",
    "        new_sentences.append(new_sen)\n",
    "\n",
    "    return np.array(new_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集shape：  (4736,)\n",
      "测试集shape：  (1185,)\n",
      "(4736,)\n"
     ]
    }
   ],
   "source": [
    "# 转为数字索引形式\n",
    "\n",
    "X_train = text_to_index_array(new_dic, X_train_l)\n",
    "\n",
    "X_test = text_to_index_array(new_dic, X_test_l)\n",
    "print( u\"训练集shape： \", X_train.shape)\n",
    "print(u\"测试集shape： \", X_test.shape)\n",
    "y_train = np.array(y_train_l)  # 转numpy数组\n",
    "y_test = np.array(y_test_l)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "vocab_dim = 100  # 向量维度\n",
    "maxlen = 140  # 文本保留的最大长度\n",
    "batch_size = 32\n",
    "n_epoch = 100\n",
    "input_length = 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)\n",
    "earlystop_lr = keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,min_delta=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(p_n_symbols, p_embedding_weights, p_X_train, p_y_train, p_X_test, p_y_test):\n",
    "    print (u'创建模型...')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(output_dim=vocab_dim,\n",
    "                        input_dim=p_n_symbols,\n",
    "                        mask_zero=True,\n",
    "                        weights=[p_embedding_weights],\n",
    "                        input_length=input_length))\n",
    "\n",
    "    model.add(LSTM(output_dim=50,\n",
    "                   activation='sigmoid',\n",
    "                   inner_activation='hard_sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    print (u'编译模型...')\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print (u\"训练...\")\n",
    "    print(model.summary())\n",
    "    model.fit(p_X_train, p_y_train, batch_size=batch_size, nb_epoch=n_epoch,\n",
    "              validation_data=(p_X_test, p_y_test),\n",
    "             callbacks=[reduce_lr,earlystop_lr])\n",
    "    \n",
    "    print (u\"评估...\")\n",
    "    score, acc = model.evaluate(p_X_test, p_y_test, batch_size=batch_size)\n",
    "    print ('Test score:', score)\n",
    "    print ('Test accuracy:', acc)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "X_train shape: (4736, 140)\n",
      "X_test shape: (1185, 140)\n",
      "创建模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\1installs\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"sigmoid\", units=50, recurrent_activation=\"hard_sigmoid\")`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编译模型...\n",
      "训练...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 140, 100)          3657300   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,687,551\n",
      "Trainable params: 3,687,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From D:\\1installs\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\1installs\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4736 samples, validate on 1185 samples\n",
      "Epoch 1/100\n",
      "4736/4736 [==============================] - 72s 15ms/step - loss: -4.1414 - acc: 0.4996 - val_loss: -6.8313 - val_acc: 0.4878\n",
      "Epoch 2/100\n",
      "4736/4736 [==============================] - 76s 16ms/step - loss: -8.0402 - acc: 0.5091 - val_loss: -10.2437 - val_acc: 0.4878\n",
      "Epoch 3/100\n",
      "4736/4736 [==============================] - 69s 15ms/step - loss: -10.7233 - acc: 0.5091 - val_loss: -12.7043 - val_acc: 0.4878\n",
      "Epoch 4/100\n",
      "4736/4736 [==============================] - 75s 16ms/step - loss: -11.6699 - acc: 0.5091 - val_loss: -12.8873 - val_acc: 0.4878\n",
      "Epoch 5/100\n",
      "4736/4736 [==============================] - 72s 15ms/step - loss: -11.9882 - acc: 0.5091 - val_loss: -12.8884 - val_acc: 0.4878\n",
      "Epoch 6/100\n",
      "4736/4736 [==============================] - 71s 15ms/step - loss: -12.0745 - acc: 0.5091 - val_loss: -12.8879 - val_acc: 0.4878\n",
      "Epoch 7/100\n",
      "4736/4736 [==============================] - 84s 18ms/step - loss: -12.1457 - acc: 0.5091 - val_loss: -12.8884 - val_acc: 0.4878\n",
      "Epoch 8/100\n",
      "4736/4736 [==============================] - 91s 19ms/step - loss: -12.1799 - acc: 0.5091 - val_loss: -12.8881 - val_acc: 0.4878\n",
      "Epoch 9/100\n",
      "4736/4736 [==============================] - 80s 17ms/step - loss: -12.1884 - acc: 0.5091 - val_loss: -12.8867 - val_acc: 0.4878\n",
      "Epoch 10/100\n",
      "4192/4736 [=========================>....] - ETA: 9s - loss: -12.2597 - acc: 0.5083 "
     ]
    }
   ],
   "source": [
    "# 将句子截取相同的长度maxlen，不够的补0\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "models = train_lstm(n_symbols, embedding_weights, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
